{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "import copy\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io\n",
    "import io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Выбор путей для файлов\n",
    "dataDir='../coco_dataset/' \n",
    "imagesDirTrain = '{}train2017'.format(dataDir)\n",
    "imagesDirVal = '{}val2017'.format(dataDir)\n",
    "\n",
    "annTrainFile = '{}annotations/captions_train2017.json'.format(dataDir)\n",
    "annValFile = '{}annotations/captions_val2017.json'.format(dataDir)\n",
    "\n",
    "#Транформация картинки к необходимым размерам\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                             transforms.ToTensor(), \n",
    "                                             transforms.Normalize(\n",
    "                                                 mean=[0.485, 0.456, 0.406],\n",
    "                                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "#Стандартизация рандома на устройствах\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Переводит нампи-изображение в формат библиотеки PIL (для transform)\n",
    "def numpy2image(img_numpy):\n",
    "    if img_numpy.dtype == np.dtype('float64'):\n",
    "        img_numpy = (img_numpy*255).astype('uint8')\n",
    "    return Image.fromarray(img_numpy)\n",
    "\n",
    "#Обвязка датасета для работы с нейронной сетью\n",
    "class MSCOCODataset(Dataset):\n",
    "    \"\"\"MSCOCO Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, annFile, imagesDir, transform=None):\n",
    "        self.coco = COCO(annFile)  #API для датасета\n",
    "        self.imagesDir = imagesDir #Путь до папки\n",
    "        self.imageids = self.coco.getImgIds() #ID изображений\n",
    "        self.transform = transform  #Транформация картинки\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco.dataset['images']) #Длина датасета\n",
    "\n",
    "    def __getitem__(self, idx):   #Возвращает словарь {изображение - ID}\n",
    "        imid = self.imageids[idx]\n",
    "        img_data = self.coco.loadImgs([imid])[0]\n",
    "        \n",
    "        img_file_name = '{}/{}'.format(self.imagesDir, img_data['file_name']) #Путь к картинке\n",
    "        image = skimage.io.imread(img_file_name) #Чтение этой картинки\n",
    "        \n",
    "        if len(image.shape) != 3:\n",
    "            return self.__getitem__(0)  #Возвращает вместо черно-бело картинки любую другую цветную\n",
    "        \n",
    "        image = numpy2image(image)     #Из нампи в Pil\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image) #Из Pil в трансформированный тензор\n",
    "            \n",
    "        sample = {'image': image, 'id': imid}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.76s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#Создание датасетов\n",
    "train_dataset = MSCOCODataset(annTrainFile, imagesDirTrain, transform)\n",
    "test_dataset = MSCOCODataset(annValFile, imagesDirVal, transform)\n",
    "\n",
    "#Разбиение датасетов на бачи\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Обработка лоадера и возврат матрицы вероятностей\n",
    "def images2vec(loader, cnn):        \n",
    "    res = None\n",
    "    res_ids = None\n",
    "    \n",
    "    for item in tqdm(loader):\n",
    "            \n",
    "        X = Variable(item['image'].type(torch.FloatTensor))\n",
    "        ids = item['id']\n",
    "            \n",
    "        vec = cnn.forward(X).data #Запуск нейронной сети\n",
    "        vec = vec.view(vec.size(0), -1)#Изменение размерности\n",
    "        \n",
    "        if res is None:\n",
    "            res = vec\n",
    "            res_ids = ids\n",
    "        else:s\n",
    "            res = torch.cat((res, vec), 0)         #Обьединение результата по всем бачам\n",
    "            res_ids = torch.cat((res_ids, ids), 0)\n",
    "    return res, res_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = models.resnet152(pretrained=True)   #Создание нейронной сети (Реснет - лучшая из предобученных сетей)\n",
    "cnn = nn.Sequential(*list(cnn.children())[:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [1:09:31<00:00,  1.13s/it]\n",
      "100%|██████████| 157/157 [01:54<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "train, train_ids = images2vec(train_dataloader, cnn) #Запуск нейронной сети на датасетах\n",
    "test, test_ids = images2vec(test_dataloader, cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(train, 'train_image_resnet.pth')    #Сохранение результатов нейронки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(train_ids, 'train_image_ids_resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(test, 'test_image_resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(test_ids, 'test_image_ids_resnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
